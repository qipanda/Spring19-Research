{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant modules\n",
    "%matplotlib notebook\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from Models.SGNS import SRCTClassifier, SRCTModel\n",
    "from Preprocessing.FullContextProcessor import FullContextProcessor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Trained SRCT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mappings and original data\n",
    "fcp = FullContextProcessor(data_fpath=\"../Data/OConnor2013/ocon-nicepaths-extracted.txt\", sep=\"\\t\")\n",
    "\n",
    "# Create monthly time id's\n",
    "fcp.createMonthTimeIdx(\"DATE\", \"TIME\")\n",
    "\n",
    "# Create mappings\n",
    "fcp.createTwoWayMap(\"SOURCE\")\n",
    "fcp.createTwoWayMap(\"RECEIVER\")\n",
    "fcp.createTwoWayMap(\"PRED\")\n",
    "fcp.convertColToIdx(\"SOURCE\")\n",
    "fcp.convertColToIdx(\"RECEIVER\")\n",
    "fcp.convertColToIdx(\"PRED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = SRCTModel(s_cnt=len(fcp.df[\"SOURCE\"].unique()),\n",
    "                    r_cnt=len(fcp.df[\"RECEIVER\"].unique()),\n",
    "                    p_cnt=len(fcp.df[\"PRED\"].unique()),\n",
    "                    T=len(fcp.df[\"TIME\"].unique()),\n",
    "                    K_s=100,\n",
    "                    K_r=100,\n",
    "                    K_p=200)\n",
    "\n",
    "model.load_state_dict(torch.load(\"srct-K200-lr1-alpha1e5-lam1e-9.pt\", map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365623, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcp.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the emebddings into numpy arrays\n",
    "s_embeds = model.s_embeds.weight.detach().numpy()\n",
    "r_embeds = model.r_embeds.weight.detach().numpy()\n",
    "p_embeds = model.p_embeds.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dash PCA data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create dataframes carrying the keys for embeddings (only care about sr's that appeared in data)\n",
    "sr_df = fcp.df.loc[:, [\"SOURCE\", \"RECEIVER\", \"TIME\", \"YEAR\", \"MONTH\"]].drop_duplicates().reset_index(drop=True)\n",
    "p_df = fcp.df.loc[:, [\"PRED\"]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Create numpy version of all valid sr embeds, append to with pred embeds for PCA\n",
    "K = 200\n",
    "sr_embeds = np.empty((sr_df.shape[0], K))\n",
    "for i, row in sr_df.iterrows():\n",
    "    sr_embeds[i, :] = np.concatenate((\n",
    "        s_embeds[row[\"SOURCE\"] + model.s_cnt*row[\"TIME\"], :], r_embeds[row[\"RECEIVER\"] + model.r_cnt*row[\"TIME\"], :]))\n",
    "    \n",
    "srp_embeds = np.concatenate((sr_embeds, p_embeds), axis=0) # order is preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA on embeddings\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data so each dim is mean = 0 std = 1\n",
    "scaler = StandardScaler()\n",
    "srp_scaled = scaler.fit_transform(X=srp_embeds)\n",
    "\n",
    "# Apply PCA to scaled data\n",
    "pca = PCA(n_components=2, svd_solver=\"full\")\n",
    "srp_reduced = pca.fit_transform(X=srp_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in dataframes with PCA projected coordinates\n",
    "sr_df.loc[:, \"X\"] = pd.Series(srp_reduced[:sr_embeds.shape[0], 0])\n",
    "sr_df.loc[:, \"Y\"] = pd.Series(srp_reduced[:sr_embeds.shape[0], 1])\n",
    "p_df.loc[:, \"X\"] = pd.Series(srp_reduced[sr_embeds.shape[0]:, 0])\n",
    "p_df.loc[:, \"Y\"] = pd.Series(srp_reduced[sr_embeds.shape[0]:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes for visualization\n",
    "sr_df.to_csv(\"sr_df.csv\")\n",
    "p_df.to_csv(\"p_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dash Plot data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes carrying the keys for embeddings (only care about sr's that appeared in data)\n",
    "sr_df = fcp.df.loc[:, [\"SOURCE\", \"RECEIVER\", \"TIME\", \"YEAR\", \"MONTH\"]]\n",
    "sr_df.drop_duplicates(inplace=True)\n",
    "sr_df.sort_values(by=\"TIME\", inplace=True)\n",
    "sr_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numpy version of all valid sr embeds, append to with pred embeds for PCA\n",
    "K = 200\n",
    "sr_embeds = np.empty((sr_df.shape[0], K))\n",
    "for i, row in sr_df.iterrows():\n",
    "    sr_embeds[i, :] = np.concatenate((\n",
    "        s_embeds[row[\"SOURCE\"] + model.s_cnt*row[\"TIME\"], :], r_embeds[row[\"RECEIVER\"] + model.r_cnt*row[\"TIME\"], :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert source and receivers to string names\n",
    "sr_df.loc[:, \"SOURCE\"] = sr_df.loc[:, \"SOURCE\"].apply(lambda x: fcp.twoway_maps[\"SOURCE\"][\"idx_to_col\"][x])\n",
    "sr_df.loc[:, \"RECEIVER\"] = sr_df.loc[:, \"RECEIVER\"].apply(lambda x: fcp.twoway_maps[\"RECEIVER\"][\"idx_to_col\"][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pr(+|p, s, r, t) for each srt-p combination\n",
    "srt_p_sig = 1.0/(1.0 + np.exp(-np.dot(sr_embeds, p_embeds.T)))\n",
    "srt_p_sig_sorted = np.argsort(-srt_p_sig) # (argsort finds min to max, negative to do max to min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save sr_df, srt_p_sig, srt_p_sig_sorted for use in viz\n",
    "sr_df.to_csv(\"sr_df.csv\")\n",
    "np.savetxt(fname=\"sr_embeds.csv\", X=sr_embeds, delimiter=\",\")\n",
    "np.savetxt(fname=\"p_embeds.csv\", X=p_embeds, delimiter=\",\")\n",
    "\n",
    "with open('pred_map.pickle', 'wb') as handle:\n",
    "    pickle.dump(fcp.twoway_maps[\"PRED\"][\"idx_to_col\"], handle)\n",
    "\n",
    "# with open('pred_map.pickle', 'rb') as handle:\n",
    "#     pred_map = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SOURCE  RECEIVER\n",
       "ISR     PSE         226\n",
       "USA     IGOUNO      221\n",
       "ISR     LBN         206\n",
       "USA     ISR         204\n",
       "ISR     USA         204\n",
       "CHN     USA         203\n",
       "USA     IRQ         196\n",
       "JPN     USA         194\n",
       "IRQ     USA         194\n",
       "USA     RUS         194\n",
       "        JPN         193\n",
       "IGOUNO  IRQ         193\n",
       "RUS     USA         192\n",
       "PSE     ISR         191\n",
       "USA     CHN         190\n",
       "IGOUNO  USA         190\n",
       "GBR     USA         189\n",
       "FRA     USA         188\n",
       "USA     IRN         185\n",
       "EGY     ISR         183\n",
       "ISR     SYR         182\n",
       "IRN     USA         181\n",
       "IRQ     IGOUNO      178\n",
       "CHN     TWN         178\n",
       "IND     PAK         177\n",
       "TWN     CHN         175\n",
       "FRA     IGOUNO      175\n",
       "USA     PSE         174\n",
       "CHN     IGOUNO      174\n",
       "        RUS         173\n",
       "                   ... \n",
       "ESP     IGOUNO       63\n",
       "USA     HRV          62\n",
       "IRL     IGOEEC       62\n",
       "TWN     IGOUNO       61\n",
       "ITA     IGOUNO       61\n",
       "DNK     IRQ          61\n",
       "FRA     CIV          60\n",
       "BGR     IRQ          58\n",
       "BIH     SRB          55\n",
       "ALB     KSV          54\n",
       "HRV     BIH          54\n",
       "SRB     HRV          52\n",
       "KOR     IRQ          52\n",
       "FRA     RWA          52\n",
       "IGONAT  MKD          50\n",
       "RUS     BIH          49\n",
       "IGOEEC  KSV          48\n",
       "GBR     BIH          47\n",
       "FRA     BIH          47\n",
       "SDN     TCD          47\n",
       "HRV     SRB          45\n",
       "IGONAT  IRQ          43\n",
       "PHL     IRQ          43\n",
       "TCD     SDN          43\n",
       "IGONAT  IRN          41\n",
       "PAK     IRQ          41\n",
       "ESP     IRQ          40\n",
       "BIH     HRV          38\n",
       "IGONAT  GEO          33\n",
       "BIH     IGONAT       32\n",
       "Length: 421, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_df.groupby([\"SOURCE\", \"RECEIVER\"]).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcp.twoway_maps[\"SOURCE\"][\"col_to_idx\"][\"CHN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcp.twoway_maps[\"RECEIVER\"][\"col_to_idx\"][\"JPN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(\"sr_embeds.txt\", \"w\") as embed_f, open(\"sr_labels.txt\", \"w\") as label_f:    \n",
    "    # write header for labels\n",
    "    label_f.write(\"TYPE\\tTIME-NAME\\n\")\n",
    "    \n",
    "    # write all the predicate embeddings\n",
    "    for p in range(model.p_cnt):\n",
    "        embed_f.write(\"\\t\".join([str(p_val) for p_val in p_embeds[p]]) + \"\\n\")\n",
    "        label_f.write(\"PRED\\t{}\\n\".format(fcp.twoway_maps[\"PRED\"][\"idx_to_col\"][p]))\n",
    "        \n",
    "    # write all sr-combination embeddings\n",
    "    for t in range(model.T):\n",
    "        s=6\n",
    "        r=30\n",
    "        sr_embed = np.concatenate((s_embeds[s + model.s_cnt*t, :], r_embeds[r + model.r_cnt*t, :]))\n",
    "        embed_f.write(\"\\t\".join([str(sr_val) for sr_val in sr_embed]) + \"\\n\")\n",
    "        label_f.write(\"C1C2\\t{}\\n\".format(\n",
    "            str(t) + \\\n",
    "            \"-\" + \\\n",
    "            fcp.twoway_maps[\"SOURCE\"][\"idx_to_col\"][s] + \\\n",
    "            \"-\" + \\\n",
    "            fcp.twoway_maps[\"RECEIVER\"][\"idx_to_col\"][r]))\n",
    "            \n",
    "#         for (s, r), _ in fcp.df.groupby([\"SOURCE\", \"RECEIVER\"]):\n",
    "#             sr_embed = np.concatenate((s_embeds[s + model.s_cnt*t, :], r_embeds[r + model.r_cnt*t, :]))\n",
    "#             embed_f.write(\"\\t\".join([str(sr_val) for sr_val in sr_embed]) + \"\\n\")\n",
    "#             label_f.write(\"C1C2\\t{}\\n\".format(\n",
    "#                 str(t) + \\\n",
    "#                 \"-\" + \\\n",
    "#                 fcp.twoway_maps[\"SOURCE\"][\"idx_to_col\"][s] + \\\n",
    "#                 \"-\" + \\\n",
    "#                 fcp.twoway_maps[\"RECEIVER\"][\"idx_to_col\"][r]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
